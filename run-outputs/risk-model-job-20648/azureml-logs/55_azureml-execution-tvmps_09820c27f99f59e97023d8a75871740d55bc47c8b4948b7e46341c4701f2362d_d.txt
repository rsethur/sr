2021-09-18T01:43:00Z Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=90001 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/configs/workspaceblobstore.cfg --log-level=LOG_WARNING
2021-09-18T01:43:00Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore
2021-09-18T01:43:01Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:01Z Starting output-watcher...
2021-09-18T01:43:01Z IsDedicatedCompute == True, won't poll for Low Pri Preemption
2021-09-18T01:43:02Z Executing 'Copy ACR Details file' on 10.0.0.6
2021-09-18T01:43:02Z Copy ACR Details file succeeded on 10.0.0.6. Output: 
>>>   
>>>   
Login Succeeded
Using default tag: latest
latest: Pulling from azureml/azureml_394e2e840889e83d9ee77a40dd82b83c
Digest: sha256:68dd8d46803d020fbdd4a4b78ba50f39744c516c6b480829f3081b542e0011f6
Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_394e2e840889e83d9ee77a40dd82b83c:latest
viennaglobal.azurecr.io/azureml/azureml_394e2e840889e83d9ee77a40dd82b83c:latest
2021-09-18T01:43:03Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:03Z Check if container risk-model-job-20648 already exist exited with 0, 

653f341a3e90848430903e4b8546993522d6be5eddbdf82e969c4ac3e8a0e853
2021-09-18T01:43:03Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
2021-09-18T01:43:03Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-b841c221cfd69f62bc4f67ce7b3efbf5-efcad6c550611ad8-01 -sshRequired=false] 
2021/09/18 01:43:03 Starting App Insight Logger for task:  containerSetup
2021/09/18 01:43:03 Version: 3.0.01719.0004 Branch: .SourceBranch Commit: a462f58
2021/09/18 01:43:03 Entered ContainerSetupTask - Preparing infiniband
2021/09/18 01:43:03 Starting infiniband setup
2021/09/18 01:43:03 Python Version found is Python 3.7.11

2021/09/18 01:43:03 Returning Python Version as 3.7
2021-09-18T01:43:03Z VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04
2021-09-18T01:43:03Z Not setting up Infiniband in Container
2021/09/18 01:43:03 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04
2021/09/18 01:43:03 VMSize: standard_d2_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04
2021/09/18 01:43:03 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false
2021/09/18 01:43:03 Not setting up Infiniband in Container
2021/09/18 01:43:03 Not setting up Infiniband in Container
2021/09/18 01:43:03 Python Version found is Python 3.7.11

2021/09/18 01:43:03 Returning Python Version as 3.7
2021/09/18 01:43:03 sshd inside container not required for job, skipping setup.
2021/09/18 01:43:04 All App Insights Logs was sent successfully or the close timeout of 10 was reached
2021/09/18 01:43:04 App Insight Client has already been closed
2021/09/18 01:43:04 Not exporting to RunHistory as the exporter is either stopped or there is no data.
Stopped: false
OriginalData: 1
FilteredData: 0.
2021-09-18T01:43:04Z Starting docker container succeeded.
2021-09-18T01:43:07Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:07Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:08Z Job environment preparation succeeded on 10.0.0.6. Output: 
>>>   2021/09/18 01:43:00 Starting App Insight Logger for task:  prepareJobEnvironment
>>>   2021/09/18 01:43:00 Version: 3.0.01719.0004 Branch: .SourceBranch Commit: a462f58
>>>   2021/09/18 01:43:00 runtime.GOOS linux
>>>   2021/09/18 01:43:00 Checking if '/tmp' exists
>>>   2021/09/18 01:43:00 Reading dyanamic configs
>>>   2021/09/18 01:43:00 Container sas url: https://baiscriptscbnprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=FKTDvEBYMS%2FS1Y26N8tk0%2FaXrTKE8G0jLlp4LK7Coxw%3D
>>>   2021/09/18 01:43:00 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: true. Is Azsecpack installation enabled: true,AzSecPack_RoleInstance="diagnosticserver-6bd557f688-jkbb8"
>>>   2021/09/18 01:43:00 Starting Azsecpack installation on machine: 7f11e2e2e39f491ab773b613b9e70f5b000003#72f988bf-86f1-41af-91ab-2d7cd011db47#6560575d-fa06-4e7d-95fb-f962e74efd7a#sethucanary#canaryws#cpu-cluster#tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d
>>>   2021/09/18 01:43:00 Is Azsecpack enabled: true, GetDisableVsatlsscan: true
>>>   2021/09/18 01:43:00 Start preparing environment for azsecpack installation. MachineName is 7f11e2e2e39f491ab773b613b9e70f5b000003 
>>>   
>>>   2021/09/18 01:43:00 
>>>   2021/09/18 01:43:00 
>>>   2021/09/18 01:43:00 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber
>>>   2021/09/18 01:43:00 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:00 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:00 Get GPU count failed with err: The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., 
>>>   2021/09/18 01:43:00 AMLComputeXDSEndpoint:  https://eastus2euap.cert.api.azureml.ms/xdsbatchai
>>>   2021/09/18 01:43:00 AMLComputeXDSApiVersion:  2018-02-01
>>>   2021/09/18 01:43:00 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/config
>>>   2021/09/18 01:43:00 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.
>>>   2021/09/18 01:43:00 Starting identity responder.
>>>   2021/09/18 01:43:00 Starting identity responder.
>>>   2021/09/18 01:43:00 Logfile used for identity responder: /mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/IdentityResponderLog-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:00 Logfile used for identity responder: /mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/IdentityResponderLog-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:00 Started Identity Responder for job.
>>>   2021/09/18 01:43:00 Started Identity Responder for job.
>>>   2021/09/18 01:43:00 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd
>>>   2021/09/18 01:43:00 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/shared
>>>   2021/09/18 01:43:00 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:00 From the policy service, the filtering patterns is: , data store is 
>>>   2021/09/18 01:43:00 Mounting job level file systems
>>>   2021/09/18 01:43:00 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts
>>>   2021/09/18 01:43:00 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/config/.amlcompute.datastorecredentials
>>>   2021/09/18 01:43:00 Datastore credentials file not found, skipping.
>>>   2021/09/18 01:43:00 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/config/.master.runtimesastokens
>>>   2021/09/18 01:43:00 Runtime sas tokens file not found, skipping.
>>>   2021/09/18 01:43:00 NFS mount is not enabled
>>>   2021/09/18 01:43:00 No Azure File Shares configured
>>>   2021/09/18 01:43:00 Mounting blob file systems
>>>   2021/09/18 01:43:00 Blobfuse runtime version 1.3.6
>>>   2021/09/18 01:43:00 Mounting azureml-blobstore-ff3896fa-5a04-44e6-b4e4-b8287eb67352 container from canaryws9594706371 account at /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore
>>>   2021/09/18 01:43:00 Using Compute Identity to authenticate Blobfuse: false.
>>>   2021/09/18 01:43:00 Using Compute Identity to authenticate Blobfuse: false.
>>>   2021/09/18 01:43:00 Blobfuse cache size set to 90001 MB.
>>>   2021/09/18 01:43:00 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=90001 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/configs/workspaceblobstore.cfg --log-level=LOG_WARNING
>>>   2021/09/18 01:43:00 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore
>>>   2021/09/18 01:43:00 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore
>>>   2021/09/18 01:43:01 Successfully mounted azureml-blobstore-ff3896fa-5a04-44e6-b4e4-b8287eb67352 container from canaryws9594706371 account at /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore
>>>   2021/09/18 01:43:01 Failed to created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore/azureml/risk-model-job-20648, due to mkdir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore/azureml/risk-model-job-20648: read-only file system
>>>   2021/09/18 01:43:01 No unmanaged file systems configured
>>>   2021/09/18 01:43:01 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:01 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:01 WorkingDirPath is specified. Setting env AZ_BATCHAI_JOB_WORK_DIR=$AZ_BATCHAI_JOB_TEMP/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:01 From the policy service, the filtering patterns is: , data store is 
>>>   2021/09/18 01:43:01 Creating working directory: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:01 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:01 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:01 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:01 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d
>>>   2021/09/18 01:43:01 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d/55_azureml-execution-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:01 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648
>>>   2021/09/18 01:43:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:01 Changing permissions for all existing files under directory: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:01 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:01 Change mode to 777 for dir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d
>>>   2021/09/18 01:43:01 Change mode to 666 for file /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d/55_azureml-execution-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:01 Set default ACL for files under directory by running: /usr/bin/setfacl -m default:g::rwx -m default:o::rwx /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/logs
>>>   2021/09/18 01:43:01 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/outputs
>>>   2021/09/18 01:43:01 Starting output-watcher...
>>>   2021/09/18 01:43:01 Single file input dataset is enabled.
>>>   2021/09/18 01:43:01 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true
>>>   2021/09/18 01:43:01 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false
>>>   2021/09/18 01:43:01 SidecarEnabled:: sidecar not enabled
>>>   2021/09/18 01:43:01 Start to pulling docker image: viennaglobal.azurecr.io/azureml/azureml_394e2e840889e83d9ee77a40dd82b83c
>>>   2021/09/18 01:43:01 Start pull docker image: viennaglobal.azurecr.io
>>>   2021/09/18 01:43:01 Getting credentials for image viennaglobal.azurecr.io/azureml/azureml_394e2e840889e83d9ee77a40dd82b83c with url viennaglobal.azurecr.io
>>>   2021/09/18 01:43:01 Container registry is ACR.
>>>   2021/09/18 01:43:01 Skip getting ACR Credentials from Identity and will be getting it from EMS
>>>   2021/09/18 01:43:01 Getting ACR Credentials from EMS for environment AzureML-sklearn-0.24-ubuntu18.04-py37-cpu:7
>>>   2021/09/18 01:43:01 Requesting XDS for registry details.
>>>   2021/09/18 01:43:01 Attempt 1 of http call to https://eastus2euap.cert.api.azureml.ms/xdsbatchai/hosttoolapi/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourceGroups/sethucanary/workspaces/canaryws/clusters/cpu-cluster/nodes/tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d?api-version=2018-02-01
>>>   2021/09/18 01:43:02 Got container registry details from credentials service for registry address: viennaglobal.azurecr.io.
>>>   2021/09/18 01:43:02 Writing ACR Details to file...
>>>   2021/09/18 01:43:02 Copying ACR Details file to worker nodes...
>>>   2021/09/18 01:43:02 Executing 'Copy ACR Details file' on 10.0.0.6
>>>   2021/09/18 01:43:02 Begin executing 'Copy ACR Details file' task on Node
>>>   2021/09/18 01:43:02 'Copy ACR Details file' task Node result: succeeded
>>>   2021/09/18 01:43:02 Copy ACR Details file succeeded on 10.0.0.6. Output: 
>>>   >>>   
>>>   >>>   
>>>   2021/09/18 01:43:02 Successfully retrieved ACR Credentials from EMS.
>>>   2021/09/18 01:43:02 EMS returned viennaglobal.azurecr.io for environment AzureML-sklearn-0.24-ubuntu18.04-py37-cpu
>>>   2021/09/18 01:43:02 Save docker credentials for image viennaglobal.azurecr.io/azureml/azureml_394e2e840889e83d9ee77a40dd82b83c in /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/docker_login_AC3A0C6F73D447B0
>>>   2021/09/18 01:43:02 Start login to the docker registry
>>>   2021/09/18 01:43:02 Successfully logged into the docker registry.
>>>   2021/09/18 01:43:02 Start run pull docker image command
>>>   2021/09/18 01:43:03 Pull docker image succeeded.
>>>   2021/09/18 01:43:03 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/docker_login_AC3A0C6F73D447B0
>>>   2021/09/18 01:43:03 Pull docker image time: 1.980885874s
>>>   
>>>   2021/09/18 01:43:03 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/09/18 01:43:03 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:03 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:03 Setting the memory limit for docker container to be 6618 MB
>>>   2021/09/18 01:43:03 The env variable file size is 38643 bytes
>>>   2021/09/18 01:43:03 Creating parent cgroup 'risk-model-job-20648' for Containers used in Job
>>>   2021/09/18 01:43:03 Add parent cgroup 'risk-model-job-20648' to container 'risk-model-job-20648'
>>>   2021/09/18 01:43:03 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false
>>>   2021/09/18 01:43:03 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,risk-model-job-20648,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/certs:/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,6618m,-v,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd:/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648:/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/risk-model-job-20648/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/risk-model-job-20648/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/config/.batchai.envlist,--cgroup-parent=/risk-model-job-20648/,--shm-size,2g
>>>   2021/09/18 01:43:03 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/risk-model-job-20648/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/risk-model-job-20648/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared 
>>>   2021/09/18 01:43:03 the binding /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648:/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648 
>>>   2021/09/18 01:43:03 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,risk-model-job-20648,-m,6618m,-w,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/config/.batchai.envlist,--cgroup-parent=/risk-model-job-20648/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648:/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648,-v,/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd:/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd,-v,/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/certs:/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/certs
>>>   2021/09/18 01:43:03 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name risk-model-job-20648 -m 6618m -w /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/config/.batchai.envlist --cgroup-parent=/risk-model-job-20648/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648:/mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648 -v /mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd:/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd -v /mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/certs:/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/certs -d -it --privileged --net=host viennaglobal.azurecr.io/azureml/azureml_394e2e840889e83d9ee77a40dd82b83c
>>>   2021/09/18 01:43:03 Check if container risk-model-job-20648 already exist exited with 0, 
>>>   
>>>   2021/09/18 01:43:03 Check if container risk-model-job-20648 already exist exited with 0, 
>>>   
>>>   2021/09/18 01:43:03 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
>>>   2021/09/18 01:43:03 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false 
>>>   2021/09/18 01:43:03 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-b841c221cfd69f62bc4f67ce7b3efbf5-efcad6c550611ad8-01 -sshRequired=false] 
>>>   2021/09/18 01:43:03 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-b841c221cfd69f62bc4f67ce7b3efbf5-efcad6c550611ad8-01 -sshRequired=false] 
>>>   2021/09/18 01:43:04 Container ssh is not required for job type.
>>>   2021/09/18 01:43:04 Starting docker container succeeded.
>>>   2021/09/18 01:43:04 Starting docker container succeeded.
>>>   2021/09/18 01:43:04 Disk space after starting docker container: 92506MB
>>>   2021/09/18 01:43:04 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true
>>>   2021/09/18 01:43:04 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false
>>>   2021/09/18 01:43:04 SidecarEnabled:: sidecar not enabled
>>>   2021/09/18 01:43:04 Begin execution of runSpecialJobTask
>>>   2021/09/18 01:43:04 Creating directory at $AZUREML_LOGDIRECTORY_PATH
>>>   2021/09/18 01:43:04 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml-logs
>>>   2021/09/18 01:43:04 runSpecialJobTask: checking control script content under dir: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore/azureml/risk-model-job-20648-setup
>>>   2021/09/18 01:43:05 Attempt 1 of http call to https://eastus2euap.api.azureml.ms/history/v1.0/private/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourceGroups/sethucanary/providers/Microsoft.MachineLearningServices/workspaces/canaryws/runs/risk-model-job-20648/spans
>>>   2021/09/18 01:43:05 runSpecialJobTask: control script dir content: [_tracer.py: size=2022 md5=4c1dd974ef27d1cbec1434a93802ac73; _tracing.py: size=26407 md5=64b473943a5d2905628a9b2097f18081; _vendor_jwt_decode.py: size=2277 md5=d4b49e48ed904f03a4d6ad2f64f17368; azureml_globals.py: size=12242 md5=3700b728b132e633c956f368d13818e4; context_managers.py: size=48073 md5=1d499aa329dc1debda235d60098e98dd; job_prep.py: size=11214 md5=13bb64f32d440c1fbaff3644045668fc; log_history_status.py: size=4428 md5=778bbe2bb6cb72340d4344366f752a63; request_utilities.py: size=1185 md5=e053daf561ffebe1c54811d9dc11beaa; run_token_provider.py: size=4228 md5=b167c8697df9c999e3676723caa93cb3; utility_context_managers.py: size=5015 md5=824d969dee21cf92733986c744d17142]
>>>   2021/09/18 01:43:05 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:05 runSpecialJobTask: Raw cmd for preparation is passed is: python /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore/azureml/risk-model-job-20648-setup/job_prep.py --snapshots '[{"Id":"f1d809b2-da38-4990-8e9b-e8f9616fb162","PathStack":["."],"SnapshotEntityId":null}]'
>>>   2021/09/18 01:43:05 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/65_job_prep-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:05 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/65_job_prep-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:05 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648;python /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore/azureml/risk-model-job-20648-setup/job_prep.py --snapshots '[{"Id":"f1d809b2-da38-4990-8e9b-e8f9616fb162","PathStack":["."],"SnapshotEntityId":null}]'
>>>   2021/09/18 01:43:05 runSpecialJobTask: commons.GetOsPlatform(): ubuntu
>>>   2021/09/18 01:43:05 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-b841c221cfd69f62bc4f67ce7b3efbf5-c9aff086ea24984e-01 -t risk-model-job-20648 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648;python /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/mounts/workspaceblobstore/azureml/risk-model-job-20648-setup/job_prep.py --snapshots '[{"Id":"f1d809b2-da38-4990-8e9b-e8f9616fb162","PathStack":["."],"SnapshotEntityId":null}]'
>>>   2021/09/18 01:43:07 containerName:risk-model-job-20648
>>>   2021/09/18 01:43:07 sidecar containerName:risk-model-job-20648
>>>   2021/09/18 01:43:07 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/09/18 01:43:07 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:07 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:07 sidecar dockerLauncher:docker
>>>   2021/09/18 01:43:07 sidecarContainerId:653f341a3e90848430903e4b8546993522d6be5eddbdf82e969c4ac3e8a0e853
>>>   2021/09/18 01:43:07 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/09/18 01:43:07 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:07 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:07 Docker logs for risk-model-job-20648
>>>   
>>>   2021/09/18 01:43:07 runSpecialJobTask: job preparation exited with code 0 and err <nil>
>>>   
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.008396] Entering job preparation.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.767106] Starting job preparation.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.767144] Extracting the control code.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.767402] Starting extract_project.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.767446] Starting to extract zip file.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.792205] Finished extracting zip file.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.798194] Using urllib.request Python 3.0 or later
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.798497] Start fetching snapshots.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.798545] Start fetching snapshot.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:06.798567] Retrieving project from snapshot: f1d809b2-da38-4990-8e9b-e8f9616fb162
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 43
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.170844] Finished fetching snapshot.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.170902] Finished fetching snapshots.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.170915] Finished extract_project.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.170997] Finished fetching and extracting the control code.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.176543] Start run_history_prep.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.177094] downloadDataStore - Download from datastores if requested.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.191343] Entering context manager injector.
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.196357] downloadDataStore completed
>>>   2021/09/18 01:43:07 runSpecialJobTask: preparation: [2021-09-18T01:43:07.197936] Job preparation is complete.
>>>   2021/09/18 01:43:07 DockerSideCarContainerLogs:
>>>   
>>>   2021/09/18 01:43:07 DockerSideCarContainerLogs End
>>>   2021/09/18 01:43:07 Execution of runSpecialJobTask completed
>>>   2021/09/18 01:43:07 Not exporting to RunHistory as the exporter is either stopped or there is no data.
>>>   Stopped: false
>>>   OriginalData: 3
>>>   FilteredData: 0.
>>>   2021/09/18 01:43:07 Process Exiting with Code:  0
>>>   2021/09/18 01:43:08 All App Insights Logs was sent successfully or the close timeout of 10 was reached
>>>   
2021-09-18T01:43:08Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:08Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:08Z 127.0.0.1 slots=2 max-slots=2
2021-09-18T01:43:08Z launching Custom job
2021-09-18T01:43:14Z job exited with code 0
2021-09-18T01:43:14Z Executing 'JobRelease task' on 10.0.0.6
2021-09-18T01:43:16Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:16Z The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
2021-09-18T01:43:17Z JobRelease task succeeded on 10.0.0.6. Output: 
>>>   2021/09/18 01:43:14 Starting App Insight Logger for task:  jobRelease
>>>   2021/09/18 01:43:14 Version: 3.0.01719.0004 Branch: .SourceBranch Commit: a462f58
>>>   2021/09/18 01:43:14 SidecarEnabled:: isDetonationChamber: false, useDockerContainer: true
>>>   2021/09/18 01:43:14 SidecarEnabled:: AmlDatasetContextManagerConfig exists: false
>>>   2021/09/18 01:43:14 SidecarEnabled:: sidecar not enabled
>>>   2021/09/18 01:43:14 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs
>>>   2021/09/18 01:43:14 runSpecialJobTask: Raw cmd for postprocessing is passed is: export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';python $AZ_BATCHAI_JOB_TEMP/azureml/risk-model-job-20648/azureml-setup/job_release.py
>>>   2021/09/18 01:43:14 runSpecialJobTask: stdout path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/75_job_post-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:14 runSpecialJobTask: stderr path for postprocessing is passed is: /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648/azureml_compute_logs/75_job_post-tvmps_09820c27f99f59e97023d8a75871740d55bc47c8b4948b7e46341c4701f2362d_d.txt
>>>   2021/09/18 01:43:14 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';python $AZ_BATCHAI_JOB_TEMP/azureml/risk-model-job-20648/azureml-setup/job_release.py
>>>   2021/09/18 01:43:14 runSpecialJobTask: commons.GetOsPlatform(): ubuntu
>>>   2021/09/18 01:43:14 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-b841c221cfd69f62bc4f67ce7b3efbf5-34c8b0a23dfe284c-01 -t risk-model-job-20648 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/8e2e53f6-eb36-469c-8f92-0359eb408aaf/job-1/risk-model-job-20648_1562d5f5-7018-43df-af29-d0214a9f3937/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/canaryws/f329699ec18a4bf4955e8b6a7c88a9a4/risk-model-job-20648/wd/azureml/risk-model-job-20648;export AZ_BATCHAI_RUN_STATUS='SUCCEEDED';export AZ_BATCHAI_LOG_UPLOAD_FAILED='false';python $AZ_BATCHAI_JOB_TEMP/azureml/risk-model-job-20648/azureml-setup/job_release.py
>>>   2021/09/18 01:43:16 containerName:risk-model-job-20648
>>>   2021/09/18 01:43:16 sidecar containerName:risk-model-job-20648
>>>   2021/09/18 01:43:16 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/09/18 01:43:16 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:16 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:16 sidecar dockerLauncher:docker
>>>   2021/09/18 01:43:16 sidecarContainerId:653f341a3e90848430903e4b8546993522d6be5eddbdf82e969c4ac3e8a0e853
>>>   2021/09/18 01:43:16 Docker Version that this nodes use are: 19.03.14+azure
>>>   
>>>   2021/09/18 01:43:16 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:16 The vmsize standard_d2_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.
>>>   2021/09/18 01:43:16 Docker logs for risk-model-job-20648
>>>   
>>>   2021/09/18 01:43:16 runSpecialJobTask: job postprocessing exited with code 0 and err <nil>
>>>   
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.054399] Entering job release
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.940832] Starting job release
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.941644] Logging experiment finalizing status in history service.
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.942203] job release stage : upload_datastore starting...Starting the daemon thread to refresh tokens in background for process with pid = 123
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: 
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.943080] job release stage : start importing azureml.history._tracking in run_history_release.
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.943148] job release stage : execute_job_release starting...
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.945997] Entering context manager injector.
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.947505] job release stage : upload_datastore completed...[2021-09-18T01:43:15.954233] job release stage : copy_batchai_cached_logs starting...
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:15.955427] job release stage : copy_batchai_cached_logs completed...
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: 
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:16.023747] job release stage : send_run_telemetry starting...
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:16.044857] get vm size and vm region successfully.
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:16.071714] get compute meta data successfully.
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:16.072436] job release stage : send_run_telemetry completed...
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:16.163259] job release stage : execute_job_release completed...
>>>   2021/09/18 01:43:16 runSpecialJobTask: postprocessing: [2021-09-18T01:43:16.163595] Job release is complete
>>>   2021/09/18 01:43:16 DockerSideCarContainerLogs:
>>>   
>>>   2021/09/18 01:43:16 DockerSideCarContainerLogs End
>>>   2021/09/18 01:43:17 All App Insights Logs was sent successfully or the close timeout of 10 was reached
>>>   2021/09/18 01:43:17 App Insight Client has already been closed
>>>   2021/09/18 01:43:17 Not exporting to RunHistory as the exporter is either stopped or there is no data.
>>>   Stopped: false
>>>   OriginalData: 3
>>>   FilteredData: 0.
>>>   
2021-09-18T01:43:17Z Executing 'Job environment clean-up' on 10.0.0.6
2021-09-18T01:43:17Z Removing container risk-model-job-20648 exited with 0, risk-model-job-20648


